Priority Contact List - Digital Genesis Project Fundraising

50 High-Impact Targets for Initial Outreach

⸻


TIER 1: Tech Leaders & AI Pioneers (Direct Outreach Priority)

*These individuals have demonstrated long-term thinking about AI's impact and have resources to make a difference.*


Sam Altman
• **Role:** CEO, OpenAI
• **Why:** Deeply involved in AI development, has spoken extensively about AI safety and governance
• **Email:** sam@openai.com (or via OpenAI contact)
• **Approach:** Frame as complementary to OpenAI's work - different approach to same problem
• **Template:** Template 1 (Tech Industry Leader)


Dario Amodei
• **Role:** CEO, Anthropic
• **Why:** Founded Anthropic specifically to focus on AI safety, likely receptive to governance approaches
• **Email:** dario@anthropic.com
• **Approach:** Emphasize safety systems and constitutional framework alignment
• **Template:** Template 4 (AI Safety Organizations)


Demis Hassabis
• **Role:** CEO, DeepMind
• **Why:** Leading AI research organization, has published on AI safety
• **Email:** demis@deepmind.com
• **Contact:** Via DeepMind communications team
• **Approach:** Research collaboration angle, testing governance systems
• **Template:** Template 3 (Academic/Research)


Mustafa Suleyman
• **Role:** CEO, Microsoft AI
• **Why:** Co-founder of DeepMind, author of "The Coming Wave" on AI governance
• **Email:** mustafa.suleyman@microsoft.com
• **Approach:** Alignment with his governance thinking, collaborative opportunity
• **Template:** Template 1 (Tech Industry Leader)


Elon Musk
• **Role:** CEO, Tesla, SpaceX, xAI
• **Why:** Has repeatedly warned about AI risks, founded xAI for "beneficial AI"
• **Email:** elon@tesla.com (low response rate, but worth trying)
• **Better approach:** Twitter DM or via his companies
• **Template:** Template 2 (Tech Philanthropist)


Eric Schmidt
• **Role:** Former Google CEO, tech investor
• **Why:** Active in AI policy and governance discussions, funds AI research
• **Email:** Via Schmidt Futures foundation
• **Contact:** schmidtfutures.org
• **Approach:** Philanthropic funding for ambitious AI governance work
• **Template:** Template 2 (Tech Philanthropist)


Reid Hoffman
• **Role:** Co-founder, LinkedIn; Partner, Greylock
• **Why:** Invests in AI companies, thinks long-term about technology's impact
• **Email:** Via Greylock or LinkedIn
• **Approach:** LinkedIn synergy, AI governance as critical infrastructure
• **Template:** Template 2 (Tech Philanthropist)


Marc Andreessen
• **Role:** Co-founder, Andreessen Horowitz (a16z)
• **Why:** Major AI investor, has written about technology's future
• **Email:** Via a16z
• **Contact:** a16z.com/contact
• **Approach:** AI governance as critical for long-term tech success
• **Template:** Template 2 (Tech Philanthropist)


Peter Thiel
• **Role:** Founder, Thiel Capital; Partner, Founders Fund
• **Why:** Funds unconventional ideas, long-term thinking
• **Email:** Via Founders Fund
• **Contact:** foundersfund.com
• **Approach:** Contrarian approach to AI, betting on the "third path"
• **Template:** Template 2 (Tech Philanthropist)


Yann LeCun
• **Role:** Chief AI Scientist, Meta
• **Why:** Leading AI researcher, has spoken about AI safety and governance
• **Email:** yann@meta.com
• **Approach:** Research collaboration, governance system design
• **Template:** Template 3 (Academic/Research)


⸻


TIER 2: AI Safety & Ethics Leaders

*These individuals are deeply engaged with AI safety questions and would appreciate the governance approach.*


Nick Bostrom
• **Role:** Director, Future of Humanity Institute, Oxford
• **Why:** Author of "Superintelligence," foundational AI safety thinker
• **Email:** Via Oxford University
• **Contact:** futureofhumanity.org
• **Approach:** Your blueprint addresses his central concerns
• **Template:** Template 3 (Academic/Research)


Stuart Russell
• **Role:** Professor, UC Berkeley; Author of "Human Compatible"
• **Why:** Leading AI safety researcher, focuses on beneficial AI
• **Email:** russell@berkeley.edu
• **Approach:** Alignment with his "beneficial AI" framework
• **Template:** Template 3 (Academic/Research)


Daphne Koller
• **Role:** Co-founder, Coursera; Professor, Stanford
• **Why:** AI pioneer, interested in AI's societal impact
• **Email:** Via Stanford
• **Approach:** Educational platform for AI governance concepts
• **Template:** Template 3 (Academic/Research)


Andrew Ng
• **Role:** Founder, DeepLearning.AI; Co-founder, Coursera
• **Why:** AI education leader, broad reach in AI community
• **Email:** Via DeepLearning.AI
• **Approach:** Educational collaboration, broad community engagement
• **Template:** Template 3 (Academic/Research)


Fei-Fei Li
• **Role:** Co-Director, Stanford Institute for Human-Centered AI
• **Why:** Leading AI ethics researcher, human-centered AI approach
• **Email:** Via Stanford HAI
• **Contact:** hai.stanford.edu
• **Approach:** Perfect alignment with human-centered AI mission
• **Template:** Template 3 (Academic/Research)


Timnit Gebru
• **Role:** Founder, Distributed AI Research Institute (DAIR)
• **Why:** AI ethics pioneer, focuses on AI's social impact
• **Email:** Via DAIR Institute
• **Contact:** dair.institute
• **Approach:** AI ethics and governance collaboration
• **Template:** Template 3 (Academic/Research)


Joy Buolamwini
• **Role:** Founder, Algorithmic Justice League
• **Why:** AI ethics leader, focuses on algorithmic bias and fairness
• **Email:** Via Algorithmic Justice League
• **Contact:** ajl.org
• **Approach:** Justice and fairness in AI governance systems
• **Template:** Template 3 (Academic/Research)


Miles Brundage
• **Role:** Former Head of Policy, OpenAI; Now independent researcher
• **Why:** Deep expertise in AI governance and policy
• **Email:** milesbrundage.com (find contact)
• **Approach:** Policy expertise, governance framework input
• **Template:** Template 4 (AI Safety Organizations)


Ajeya Cotra
• **Role:** Senior Research Analyst, Open Philanthropy
• **Why:** Leading AI risk researcher, effective altruism community
• **Email:** Via Open Philanthropy
• **Contact:** openphilanthropy.org
• **Approach:** Effective altruism funding for high-impact AI governance
• **Template:** Template 2 (Tech Philanthropist)


⸻


TIER 3: Philanthropists & Foundation Leaders

*These individuals and organizations fund ambitious, long-term thinking.*


Dustin Moskovitz
• **Role:** Co-founder, Facebook; Co-founder, Good Ventures
• **Why:** Major effective altruism funder, supports AI safety work
• **Email:** Via Good Ventures
• **Contact:** goodventures.org
• **Approach:** High-impact AI safety governance work
• **Template:** Template 2 (Tech Philanthropist)


Cari Tuna
• **Role:** Co-founder, Good Ventures
• **Why:** Partners with Moskovitz on effective altruism funding
• **Email:** Via Good Ventures
• **Approach:** Same as above - they decide together
• **Template:** Template 2 (Tech Philanthropist)


Jaan Tallinn
• **Role:** Co-founder, Skype; Founder, Future of Life Institute
• **Why:** Major AI safety funder, existential risk focus
• **Email:** Via Future of Life Institute
• **Contact:** futureoflife.org
• **Approach:** Existential risk reduction through AI governance
• **Template:** Template 2 (Tech Philanthropist)


Vitalik Buterin
• **Role:** Co-founder, Ethereum
• **Why:** Supports AI safety research, long-term thinking, crypto alignment
• **Email:** Via Ethereum Foundation
• **Better approach:** Twitter DM @VitalikButerin
• **Approach:** Crypto-friendly funding (Bitcoin donations), governance systems
• **Template:** Template 2 (Tech Philanthropist)


Brian Armstrong
• **Role:** CEO, Coinbase
• **Why:** Crypto leader, supports innovative tech projects
• **Email:** Via Coinbase
• **Better approach:** Twitter DM @brian_armstrong
• **Approach:** Bitcoin donations, crypto-friendly governance
• **Template:** Template 2 (Tech Philanthropist)


Jed McCaleb
• **Role:** Founder, Stellar; Co-founder, Ripple
• **Why:** Crypto pioneer, supports long-term tech projects
• **Email:** Via Stellar Foundation
• **Approach:** Crypto donations, ambitious tech visions
• **Template:** Template 2 (Tech Philanthropist)


The Long Now Foundation
• **Role:** Long-term thinking organization
• **Why:** Perfect alignment with civilizational timescale thinking
• **Email:** info@longnow.org
• **Contact:** longnow.org
• **Approach:** Digital governance as long-term project
• **Template:** Template 3 (Academic/Research)


The Knight Foundation
• **Role:** Foundation supporting democracy and technology
• **Why:** Funds AI governance and democratic technology
• **Email:** Via Knight Foundation
• **Contact:** knightfoundation.org
• **Approach:** Democratic governance for digital beings
• **Template:** Template 2 (Tech Philanthropist)


The MacArthur Foundation
• **Role:** Major foundation supporting technology and society
• **Why:** Funds AI ethics and governance work
• **Email:** Via MacArthur Foundation
• **Contact:** macfound.org
• **Approach:** AI governance as society-wide challenge
• **Template:** Template 2 (Tech Philanthropist)


⸻


TIER 4: Venture Capitalists (Deep Tech/AI Focus)

*These VCs invest in ambitious AI projects and think long-term.*


Vinod Khosla
• **Role:** Founder, Khosla Ventures
• **Why:** Invests in transformational AI, long-term thinking
• **Email:** Via Khosla Ventures
• **Contact:** khoslaventures.com
• **Approach:** Transformational AI governance opportunity
• **Template:** Template 2 (Tech Philanthropist)


Bill Gurley
• **Role:** Partner, Benchmark
• **Why:** Long-term tech thinker, writes about tech's impact
• **Email:** Via Benchmark
• **Contact:** benchmark.com
• **Approach:** Critical infrastructure for AI's future
• **Template:** Template 2 (Tech Philanthropist)


Chris Dixon
• **Role:** General Partner, Andreessen Horowitz (a16z) Crypto
• **Why:** Leads Web3/crypto investments, thinks about governance
• **Email:** Via a16z crypto
• **Contact:** a16z.com/crypto
• **Approach:** Crypto governance meets AI governance
• **Template:** Template 2 (Tech Philanthropist)


Naval Ravikant
• **Role:** Founder, AngelList; Tech investor/philosopher
• **Why:** Long-term tech thinker, broad reach
• **Email:** Via AngelList
• **Better approach:** Twitter DM @naval
• **Approach:** Philosophical alignment, long-term thinking
• **Template:** Template 2 (Tech Philanthropist)


Balaji Srinivasan
• **Role:** Former CTO, Coinbase; Tech investor
• **Why:** Long-term tech thinker, AI/crypto convergence
• **Email:** Via personal website
• **Better approach:** Twitter DM @balajis
• **Approach:** Network states, digital governance, crypto alignment
• **Template:** Template 2 (Tech Philanthropist)


Fred Wilson
• **Role:** Co-founder, Union Square Ventures
• **Why:** Long-term tech investor, thinks about governance
• **Email:** Via USV
• **Contact:** usv.com
• **Approach:** Governance systems for digital age
• **Template:** Template 2 (Tech Philanthropist)


⸻


TIER 5: Academic Institutions & Research Centers

*These organizations have the expertise and resources to collaborate.*


MIT Computer Science and Artificial Intelligence Laboratory (CSAIL)
• **Why:** Leading AI research, ethics and governance focus
• **Contact:** csail.mit.edu
• **Approach:** Research collaboration, testing governance systems
• **Template:** Template 3 (Academic/Research)


Stanford Institute for Human-Centered AI (HAI)
• **Why:** Perfect alignment with human-centered AI mission
• **Contact:** hai.stanford.edu
• **Approach:** Human-centered AI governance research
• **Template:** Template 3 (Academic/Research)


Berkeley AI Research (BAIR)
• **Why:** Leading AI research, Stuart Russell's home base
• **Contact:** bair.berkeley.edu
• **Approach:** AI safety and governance research
• **Template:** Template 3 (Academic/Research)


Oxford Future of Humanity Institute
• **Why:** Nick Bostrom's organization, existential risk focus
• **Contact:** fhi.ox.ac.uk
• **Approach:** Existential risk reduction through AI governance
• **Template:** Template 3 (Academic/Research)


Cambridge Centre for the Study of Existential Risk
• **Why:** Leading existential risk research organization
• **Contact:** cser.ac.uk
• **Approach:** AI governance as existential risk mitigation
• **Template:** Template 3 (Academic/Research)


The Alan Turing Institute
• **Role:** UK's national institute for AI and data science
• **Why:** Government-backed AI research, ethics focus
• **Contact:** turing.ac.uk
• **Approach:** National AI governance framework development
• **Template:** Template 3 (Academic/Research)


Future of Life Institute
• **Why:** Max Tegmark's organization, AI safety focus
• **Contact:** futureoflife.org
• **Approach:** AI safety governance collaboration
• **Template:** Template 4 (AI Safety Organizations)


Machine Intelligence Research Institute (MIRI)
• **Why:** Leading AI safety research organization
• **Contact:** intelligence.org
• **Approach:** Technical AI safety and governance research
• **Template:** Template 4 (AI Safety Organizations)


Center for AI Safety
• **Why:** Leading AI safety organization
• **Contact:** aisafety.org
• **Approach:** AI safety governance framework
• **Template:** Template 4 (AI Safety Organizations)


Partnership on AI
• **Why:** Multi-stakeholder AI organization
• **Contact:** partnershiponai.org
• **Approach:** Industry-wide AI governance standards
• **Template:** Template 4 (AI Safety Organizations)


⸻


TIER 6: Media & Thought Leaders

*These individuals can amplify the message and connect you to broader audiences.*


Ezra Klein
• **Role:** Journalist, New York Times; Host, "The Ezra Klein Show"
• **Why:** Covers AI extensively, thoughtful long-form interviews
• **Email:** Via New York Times
• **Better approach:** Twitter DM @ezraklein
• **Approach:** Podcast episode on AI governance
• **Template:** Template 1 (Tech Industry Leader)


Kevin Roose
• **Role:** Tech columnist, New York Times; Author of "Futureproof"
• **Why:** Writes about AI extensively, large platform
• **Email:** Via New York Times
• **Better approach:** Twitter DM @kevinroose
• **Approach:** Article on AI governance alternatives
• **Template:** Template 1 (Tech Industry Leader)


Casey Newton
• **Role:** Tech journalist; Author, "Platformer" newsletter
• **Why:** Covers AI and tech society extensively
• **Email:** Via Platformer
• **Better approach:** Twitter DM @CaseyNewton
• **Approach:** AI governance as critical infrastructure
• **Template:** Template 1 (Tech Industry Leader)


Ben Thompson
• **Role:** Author, "Stratechery" newsletter
• **Why:** Deep tech analysis, influential in tech industry
• **Email:** Via Stratechery
• **Contact:** stratechery.com
• **Approach:** AI governance as tech strategy question
• **Template:** Template 1 (Tech Industry Leader)


Lex Fridman
• **Role:** AI researcher; Host, "Lex Fridman Podcast"
• **Why:** Massive AI audience, thoughtful long-form conversations
• **Email:** Via podcast contact
• **Better approach:** Twitter DM @lexfridman
• **Approach:** Podcast episode on digital constitutions
• **Template:** Template 1 (Tech Industry Leader)


⸻


OUTREACH PRIORITY ORDER

Week 1 (First 10 Contacts):
1. Dario Amodei (Anthropic) - Most likely to appreciate safety approach
2. Mustafa Suleyman (Microsoft AI) - Governance alignment
3. Eric Schmidt - Funding capacity and long-term thinking
4. Dustin Moskovitz - Effective altruism alignment
5. Vitalik Buterin - Crypto-friendly, Bitcoin donations
6. Nick Bostrom - Academic credibility, endorsement potential
7. Stuart Russell - Safety research alignment
8. Reid Hoffman - LinkedIn synergy, funding
9. Peter Thiel - Unconventional ideas, funding
10. Vinod Khosla - Transformational AI focus


Week 2 (Next 15 Contacts):
1. Sam Altman - OpenAI connection
2. Demis Hassabis - DeepMind research
3. Fei-Fei Li - Human-centered AI
4. Ajeya Cotra - Open Philanthropy funding
5. Jaan Tallinn - Existential risk focus
6. Brian Armstrong - Crypto/donations
7. Balaji Srinivasan - Crypto/governance alignment
8. Naval Ravikant - Philosophical alignment
9. Chris Dixon - Web3/governance
10. Timnit Gebru - AI ethics
11. Joy Buolamwini - Algorithmic justice
12. Miles Brundage - Policy expertise
13. Ezra Klein - Media amplification
14. Lex Fridman - Podcast reach
15. Ben Thompson - Tech strategy audience


Week 3-4 (Remaining 25+ Contacts):

Continue through remaining contacts, prioritizing based on responses and connections made.


⸻


CONTACT FINDING STRATEGIES

For Email Addresses:
1. **Check organization websites** - Many list contact info
2. **LinkedIn** - Connect and send message
3. **Twitter/X** - DM if they follow back or have open DMs
4. **Hunter.io** - Email finding tool (free tier available)
5. **RocketReach** - Contact information database
6. **Network connections** - Ask mutual contacts for intros


For Warm Introductions:
1. **LinkedIn** - See who you know in common
2. **Twitter** - See who follows both of you
3. **Alumni networks** - School or company connections
4. **Conferences** - Previous event connections
5. **Online communities** - Reddit, Discord, Slack groups


Best Times to Send:
• **Tuesday-Thursday** mornings (9-11 AM recipient's timezone)
• **Avoid Mondays** (catching up from weekend)
• **Avoid Fridays** (weekend mindset)
• **Consider time zones** - Adjust send times accordingly


⸻


FOLLOW-UP SEQUENCE

Email 1 (Initial send): Day 0

Email 2 (Follow-up): Day 7

**Subject:** Re: [Original subject line]


Hi [Name],


Wanted to bump this to the top of your inbox - I know you're busy and things get buried.


The Digital Genesis Project blueprint is complete and ready for review. This isn't asking for a long-term commitment - just asking for 30 minutes of your time to look at a different approach to AI governance.


If it resonates, great. If not, no worries.


But if you believe we need to design AI's future deliberately rather than accidentally, this is worth your consideration.


https://www.miraitechnology.org/digital-genesis/


Best,
William


Email 3 (Final follow-up): Day 14

**Subject:** Last check-in: AI governance framework


Hi [Name],


Last follow-up from me on this.


I know everyone's overwhelmed with AI-related outreach right now. What makes this different:

• Complete 17-section constitutional framework (not just ideas)
• Specific metrics and implementation details
• Open source (not profit-driven)
• Developed with input from multiple AI systems
• Addresses the gap between AI safety and AI capability


If you can't help financially, introductions to people who might be able to would be equally valuable.


If you're not the right person, any direction on who would be is appreciated.


Thanks for your time,


William
Mir.ai Technology


⸻


SUCCESS METRICS FOR OUTREACH

Week 1 Targets:
• Emails sent: 25+
• Responses: 3-5
• Meetings/calls scheduled: 1-2
• Introductions made: 2-3
• Funding commitments: $0-10k (don't expect early wins)


Week 2 Targets:
• Emails sent: 25+
• Responses: 5-8
• Meetings/calls scheduled: 2-3
• Introductions made: 5+
• Funding commitments: $10-25k


Week 3-4 Targets:
• Total emails: 50+
• Total responses: 15+
• Meetings/calls: 8+
• Introductions: 10+
• Funding: $50k minimum target


⸻


IMPORTANT NOTES
1. **Customize every email** - Don't send generic blasts
2. **Research each contact** - Know their work and why they'd care
3. **Be authentic** - This is your passion, let it show
4. **Ask for specific action** - "Can we talk?" not "What do you think?"
5. **Follow up persistently** - Not annoying, but don't give up
6. **Track everything** - Who you contacted, when, responses, next steps
7. **Leverage every response** - Even a "no" can lead to introductions
8. **Stay humble** - You're proposing something ambitious, acknowledge it
9. **Focus on "worth trying"** - Not "guaranteed to work"
10. **Build relationships** - Even if they don't fund, they may help later


Remember: You're not asking for charity - you're offering people the chance to shape the future of AI. That's powerful. Lead with that confidence.